---
title: "Analyzing Spatial Data with R - exercises"
author: "Micha Silver"
date: "2025-06-03"
output:
  html_document: default
  pdf_document: default
bibliography: references.bib
always_allow_html: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Preparation

### Required packages

```{r pkgs, results='hide', message=FALSE}
pkg_list <- c("terra", "sf", "CDSE", "knitr", "leaflet", "ggplot2")
invisible(lapply(pkg_list, library, character.only = TRUE))
```

### Get CDSE credentials

#### and prepare OAuth token for API access

```{r creds, results='hide'}
creds <- read.csv("credentials.csv")
tok <- CDSE::GetOAuthToken(id = creds$clientid, secret = creds$secret)
```

### Set query parameters

- Dates
- AOI file, a polygon covering the marsh area of Doñana Park (@green_groundwater_2024)
- Which "collection" (Sentinel-2 Level L2A)

```{r params}
aoi <- sf::st_read(file.path("GIS", "Fuenteduque_aoi.gpkg"))
from_date <- "2025-01-01" 
to_date <- "2025-04-30"
collection <- "sentinel-2-l2a"
max_cloud <- 20
# Download only one Copernicus tile
tileid <- "29SQB"

# Setup Output directory
Output_dir <- "Output"
if (!dir.exists(Output_dir)) {
  dir.create(Output_dir)
}
```
## Get list of available images

```{r catalog}
img_list <- CDSE::SearchCatalog(aoi = aoi,
                                from = from_date,
                                to = to_date,
                                collection = collection,
                                token = tok)
# How many images available?
message("Number of available images: ", nrow(img_list))
```
### Remove images with high cloud cover

### Also select only one image tile, "29SQB"

```{r cloud-filter}
img_list <- img_list[img_list$tileCloudCover <= max_cloud,]
img_list <- img_list[grepl(tileid, img_list$sourceId),]
message("Number of images after cloud filtering: ", nrow(img_list))
# Sort by dates
img_list <- img_list[order(img_list$acquisitionDate),]
# Which image dates are available?
knitr::kable(img_list$acquisitionDate)
```

## Derive water surfaces

### Loop over available images

```{r water-surface}
# We already have collection from above;
# Refresh token:
tok <- CDSE::GetOAuthToken(id = creds$clientid, secret = creds$secret)

# Use lapply to loop over img_list data.frame:
water_rast_list <- lapply(1:nrow(img_list), function(i) {
  dte <- img_list$acquisitionDate[i]
  
  # Save processed water surface as Geotiff
  rast_file <- file.path(Output_dir, paste0("water_", dte, ".tif"))
  # But, if file already exists (from previous run), just skip download
  if (!file.exists(rast_file)) {
  water_rast <- CDSE::GetImage(aoi = aoi,
                               time_range = dte,
                               collection = collection,
                               script = "MNDWI_masked.js",
                               resolution = 20, # Use lower res of SWIR band
                               token = tok)
  
  terra::writeRaster(water_rast, rast_file)
  } else {
    #message("Raster file: ", rast_file, " already exists, skipping.")
  }
  return(rast_file)
})
water_rast_list <- unlist(water_rast_list)
message("Saved: ", length(water_rast_list), " water surface raster files.")
```

### Plot water surface map

```{r plot1}
# Take first water surface map in list
r <- rast(water_rast_list[1])
leaflet() |> addTiles() |>
  addRasterImage(r)
```

### Threshold to get just water surfaces

#### Using the threshold value 0.09 (@xu_modification_2006);

#### The `classify` function in `terra` is called to reclassify water surfaces.

```{r water-thresh}
thresh <- 0.09
reclass_mat <- matrix(c(-1.0, thresh, NA, thresh, 1.0, 1), ncol=3, byrow=TRUE)
reclass_mat
water_thresh_list <- lapply(water_rast_list, function(x) {
  r <- terra::classify(rast(x), reclass_mat)
  water_thresh_file <- gsub("water", "water_thresh", x)
  terra::writeRaster(r, water_thresh_file, overwrite = TRUE)
  return(water_thresh_file)
})
water_thresh_list <- unlist(water_thresh_list)
```

### Plot thresholded water surface

#### for first date in range

```{r water-thresh1}
thresh_file <- water_thresh_list[1]
r <- rast(thresh_file)
leaflet() |> 
  addTiles() |>
  addRasterImage(r, colors = "blue")
```

#### second date

```{r water-thresh2}
# and the second image
thresh_file <- water_thresh_list[2]
r <- rast(thresh_file)
leaflet() |> 
  addTiles() |>
  addRasterImage(r, colors = "blue")
```

#### last date in range

```{r water-thresh3}
# Now the last water surface map in list
thresh_file <- water_thresh_list[length(water_thresh_list)]
r <- rast(thresh_file)
leaflet() |>
  addTiles() |>
  addRasterImage(r, colors = "blue")
```

## Extract value at point for all water rasters

### Choose a sampling point

```{r sample-point}
# Show the point on map
coords <- data.frame("lon" = -6.3710,
                     "lat" = 37.0375)
pt <- terra::vect(coords, crs = "EPSG:4326")
r <- terra::rast(water_rast_list[2])
leaflet() |>
  addTiles() |>
  addRasterImage(r) |>
  addCircleMarkers(lng = coords$lon, lat = coords$lat, radius = 7,
                   fillColor = "red", stroke = FALSE, fillOpacity = 1)
```

### Extract time series of MNDWI values at that point

```{r extract}
water_val_list <- lapply(water_rast_list, function(x) {
  r <- rast(x)
  val <- terra::extract(r, pt, ID = FALSE)
  # Remove extra file name character, leave only date for plotting
  dte <- basename(x)
  dte <- gsub("water_", "", dte)
  dte <- gsub(".tif", "", dte)
  val_df <- data.frame(as.Date(dte), val)
  names(val_df) <- c("Image_date", "MNDWI")
  return(val_df)
})
# Bind list into data.frame, using rbind()
vals_df <- do.call(rbind, water_val_list)
knitr::kable(vals_df)
```

### Time series plot

```{r plot-timeseries}
ggplot(vals_df) +
  geom_col(aes(x=Image_date, y=MNDWI), fill = "blue") +
  geom_hline(aes(yintercept = 0.09,
            color = "red") ) +
  ggtitle("MNDWI values",
          subtitle = paste("at location", coords$lon, coords$lat)) +
  theme(axis.text.x = element_text(angle = 30),
        legend.position = "")
```

## Build OPTRAM model

#### Call rOPTRAM function to acquire indices

(@sadeghi_optical_2017, @babaeian_new_2019)

Using R package `rOPTRAM` (@silver_2023_roptram)

```{r acquire, results='hide', warning=FALSE, message=FALSE}
# Install package from ROpenSci github
remotes::install_github("ropensci/rOPTRAM")
library(rOPTRAM)

optram_options("max_cloud", max_cloud, show_opts = FALSE)
optram_options("plot_colors", "density", show_opts = FALSE)
optram_options("veg_index", "SAVI", show_opts = FALSE)
optram_options("rm.hi.str", TRUE, show_opts = FALSE)
optram_options("rm.low.vi", TRUE, show_opts = FALSE)
optram_options("only_vi_str", TRUE, show_opts = FALSE)
optram_options("tileid", tileid, show_opts = FALSE)
optram_options("resolution", 20)

# Acquire and process S2 based indices
# Note: optram_option "overwrite" = FALSE means that previously downloaded images will not be download again.
STR_list <- optram_acquire_s2(aoi = aoi,
                              from_date = from_date,
                              to_date = to_date, 
                              output_dir = Output_dir,
                              clientid = creds$clientid,
                              secret = creds$secret)
```


### Build OPTRAM model

```{r build}
VI_dir <- file.path(Output_dir, getOption("optram.veg_index"))
VI_list <- list.files(VI_dir, full.names = TRUE)
STR_dir <- file.path(Output_dir, "STR")
STR_list <- list.files(STR_dir, full.names = TRUE)

# Collect table of VI and STR values
# If VI_STR_df file already exists, use it (no need to recollate)
VI_STR_file <- file.path(Output_dir, "VI_STR_data.rds")
if (file.exists(VI_STR_file)) {
  VI_STR_df <- readRDS(VI_STR_file)
} else {
  VI_STR_df <- optram_ndvi_str(STR_list, VI_list,
                               output_dir = Output_dir)
}
optram_rmse <- optram_wetdry_coefficients(VI_STR_df, output_dir = Output_dir)
```

### Plot trapezoid

```{r plot-trapezoid, warning=FALSE, message=FALSE, fig.show='hide',  results = FALSE}
edges_df <- read.csv(file.path(Output_dir, "trapezoid_edges_lin.csv"))

pl <- plot_vi_str_cloud(full_df = VI_STR_df,
                  edges_df = edges_df,
                  edge_points = TRUE)
pl + ggtitle("Trapezoid Plot for Doñana Marsh", subtitle = "images from 2025")
pl_file <- "trapezoid_plot.png"
ggsave(file.path(Output_dir, pl_file),
       width=24, height=15, units = "cm")
```
#### Show plot

```{r show-plot, warning=FALSE, message=FALSE, results = FALSE}
pl
```

### Get soil moisture map for last date

```{r soil-moisture}
last_date <- as.character(img_list$acquisitionDate[nrow(img_list)])
SM <- rOPTRAM::optram_calculate_soil_moisture(
  img_date = last_date,
  VI_dir = VI_dir,  # defined above
  STR_dir = STR_dir,
  data_dir = Output_dir,
  output_dir = Output_dir)
```

### Plot soil moisture

```{r plot-sm, warning=FALSE, message=FALSE}
pal <- leaflet::colorBin("viridis",
                         domain = c(-0.10, 10.0),
                         na.color = "#00000000")
leaflet() |>
  addTiles() |>
  addRasterImage(SM, colors = pal)
```

  
<br/><br/>

## License

eLTER Workshop-Analyzing Remote Sensing Data in R 

© 2025 by Micha Silver

is licensed under Creative Commons Attribution-ShareAlike 4.0 International.

To view a copy of this license, visit

https://creativecommons.org/licenses/by-sa/4.0/

## References